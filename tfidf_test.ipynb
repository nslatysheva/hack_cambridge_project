{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#==============================================================================\n",
    "# Load in text data, split into train/test \n",
    "#==============================================================================\n",
    "\n",
    "# load in data\n",
    "os.chdir(\"/Users/natashal/Projects/consulting/peoplelikeme/analysis/\")\n",
    "reviews = pd.read_json('reviews2_30000.json')\n",
    "\n",
    "# what's the shape (rows, columns) of the data?\n",
    "print(reviews.shape); type(reviews)\n",
    "\n",
    "# get just the body and rating out for now\n",
    "reviews_br = reviews[[\"body\", \"rating\"]]\n",
    "reviews_br.head\n",
    "\n",
    "# drop entries with null values, check shape afterwards\n",
    "reviews_br = reviews_br.dropna(how='any')\n",
    "reviews_br.shape\n",
    "\n",
    "# split my data into train and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "train, test = train_test_split(reviews_br, test_size=0.2, random_state=42)\n",
    "train.shape; test.shape\n",
    "#==============================================================================\n",
    "# Process description fields of train set\n",
    "#==============================================================================\n",
    "\n",
    "# tokenize the text using countvectoriser\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(lowercase=True, stop_words='english', strip_accents='unicode')\n",
    "count_vect.get_stop_words()\n",
    "\n",
    "# if wanting to use n-grams\n",
    "count_vect = CountVectorizer(analyzer='word', ngram_range=(1,2), lowercase=True, stop_words='english', strip_accents='unicode')\n",
    "\n",
    "# fit the count vectoriser\n",
    "X_train_counts = count_vect.fit_transform(train.body)\n",
    "X_train_counts.shape\n",
    "count_vect.get_feature_names()[100:1000]\n",
    "\n",
    "# get term frequencies (tf), scale by inverse document frequenies (idf)\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(use_idf=True, smooth_idf=True)\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape\n",
    "\n",
    "# explore the matrix by converting back to dense format\n",
    "dense=X_train_tfidf.todense()\n",
    "dense[1,1]\n",
    "\n",
    "#==============================================================================\n",
    "# Training classifiers \n",
    "#==============================================================================\n",
    "###################### 1) Start with naive bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier_NB = MultinomialNB()\n",
    "# train NB classifier\n",
    "classifier_NB_fit = classifier_NB.fit(X_train_tfidf, train.rating)\n",
    "                    \n",
    "# predict ratings on test set using model                    \n",
    "test_counts = count_vect.transform(test.body)\n",
    "test_tfidf = tfidf_transformer.transform(test_counts)\n",
    "predicted_nb = classifier_NB_fit.predict(test_tfidf)\n",
    "\n",
    "## get accuracy i.e. how often the predicted value eqausl the target values\n",
    "print(\"NB accuracy\", np.mean(predicted_nb == test.rating))\n",
    "\n",
    "####################### 2) train the linear SVM \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier_svm = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "classifier_svm_fit = classifier_svm.fit(X_train_tfidf, train.rating)                               \n",
    "                               \n",
    "# predict ratings on test set using model\n",
    "predicted_svm = classifier_svm_fit.predict(test_tfidf) \n",
    "\n",
    "# get accuracy again, to compare to NB\n",
    "print(\"SVM accuracy\", np.mean(predicted_svm == test.rating))\n",
    "\n",
    "#==============================================================================\n",
    "# Detailed performance metrics\n",
    "#==============================================================================\n",
    "# write out classification performance report\n",
    "from sklearn import metrics\n",
    "report = metrics.classification_report(test.rating, predicted_svm)\n",
    "print(report)\n",
    "\n",
    "# write out confusion matrix\n",
    "confusion = metrics.confusion_matrix(test.rating, predicted_svm)\n",
    "print(confusion)\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, title=\"Confusion matrix\"):\n",
    "    plt.matshow(confusion_matrix) \n",
    "    plt.xticks([0, 1, 2, 3, 4], [1, 2, 3, 4, 5])\n",
    "    plt.yticks([0, 1, 2, 3, 4], [1, 2, 3, 4, 5])\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plot_confusion_matrix(confusion)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "confusion_normalized = confusion.astype('float') / confusion.sum(axis=1)[:, np.newaxis]\n",
    "print(confusion_normalized)\n",
    "plot_confusion_matrix(confusion_normalized, title=\"Normalised confusion matrix\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
